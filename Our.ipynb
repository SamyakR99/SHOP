{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140de5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './')\n",
    "sys.path.insert(0, '../')\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "# from dataloaders.helper import CutoutPIL\n",
    "from randaugment import RandAugment\n",
    "\n",
    "from PIL import ImageDraw\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# __all__ = ['CutoutPIL']\n",
    "\n",
    "\n",
    "class CutoutPIL(object):\n",
    "    def __init__(self, cutout_factor=0.5):\n",
    "        self.cutout_factor = cutout_factor\n",
    "\n",
    "    def __call__(self, x):\n",
    "        img_draw = ImageDraw.Draw(x)\n",
    "        h, w = x.size[0], x.size[1]  # HWC\n",
    "        h_cutout = int(self.cutout_factor * h + 0.5)\n",
    "        w_cutout = int(self.cutout_factor * w + 0.5)\n",
    "        y_c = np.random.randint(h)\n",
    "        x_c = np.random.randint(w)\n",
    "\n",
    "        y1 = np.clip(y_c - h_cutout // 2, 0, h)\n",
    "        y2 = np.clip(y_c + h_cutout // 2, 0, h)\n",
    "        x1 = np.clip(x_c - w_cutout // 2, 0, w)\n",
    "        x2 = np.clip(x_c + w_cutout // 2, 0, w)\n",
    "        fill_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "        img_draw.rectangle([x1, y1, x2, y2], fill=fill_color)\n",
    "\n",
    "        return x\n",
    "\n",
    "class foodseg103(data.Dataset):\n",
    "    def __init__(self, root, data_split, img_size=224, p=1, annFile=\"\", label_mask=None, partial=1+1e-6):\n",
    "        # data_split = train / val\n",
    "        self.root = root\n",
    "        self.classnames = [\"candy\", \"egg tart\", \"french fries\", \"chocolate\", \"biscuit\", \"popcorn\", \"pudding\", \"ice cream\", \"cheese butter\", \"cake\", \"wine\", \"milkshake\", \"coffee\", \"juice\", \"milk\", \"tea\", \"almond\", \"red beans\", \"cashew\", \"dried cranberries\", \"soy\", \"walnut\", \"peanut\", \"egg\", \"apple\", \"date\", \"apricot\", \"avocado\", \"banana\", \"strawberry\", \"cherry\", \"blueberry\", \"raspberry\", \"mango\", \"olives\", \"peach\", \"lemon\", \"pear\", \"fig\", \"pineapple\", \"grape\", \"kiwi\", \"melon\", \"orange\", \"watermelon\", \"steak\", \"pork\", \"chicken duck\", \"sausage\", \"fried meat\", \"lamb\", \"sauce\", \"crab\", \"fish\", \"shellfish\", \"shrimp\", \"soup\", \"bread\", \"corn\", \"hamburg\", \"pizza\", \"hanamaki baozi\", \"wonton dumplings\", \"pasta\", \"noodles\", \"rice\", \"pie\", \"tofu\", \"eggplant\", \"potato\", \"garlic\", \"cauliflower\", \"tomato\", \"kelp\", \"seaweed\", \"spring onion\", \"rape\", \"ginger\", \"okra\", \"lettuce\", \"pumpkin\", \"cucumber\", \"white radish\", \"carrot\", \"asparagus\", \"bamboo shoots\", \"broccoli\", \"celery stick\", \"cilantro mint\", \"snow peas\", \"cabbage\", \"bean sprouts\", \"onion\", \"pepper\", \"green beans\", \"French beans\", \"king oyster mushroom\", \"shiitake\", \"enoki mushroom\", \"oyster mushroom\", \"white button mushroom\", \"salad\", \"other ingredients\"]\n",
    "        \n",
    "        self.data_split = data_split\n",
    "        if data_split == 'trainval':\n",
    "            self.labels_lab = np.load('/home/samyakr2/food/FoodSeg103/train_labels.npy', allow_pickle=True).item()\n",
    "        \n",
    "        if data_split == 'test':\n",
    "            self.labels_lab = np.load('/home/samyakr2/food/FoodSeg103/test_labels.npy', allow_pickle=True).item()\n",
    "            \n",
    "        \n",
    "        if annFile == \"\":\n",
    "            self.annFile = os.path.join(self.root, 'Annotations')\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        image_list_file = os.path.join('/home/samyakr2/food/FoodSeg103', 'ImageSets', '%s.txt' % data_split)\n",
    "\n",
    "        with open(image_list_file) as f:\n",
    "            image_list = f.readlines()\n",
    "        self.image_list = [a.strip() for a in image_list]\n",
    "\n",
    "        \n",
    "        if data_split == 'Train':\n",
    "            num_examples = len(self.image_list)\n",
    "            pick_example = int(num_examples * p)\n",
    "            self.image_list = self.image_list[:pick_example]\n",
    "        else:\n",
    "            self.image_list = self.image_list\n",
    "\n",
    "        train_transform = transforms.Compose([\n",
    "            # transforms.RandomResizedCrop(img_size)\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            CutoutPIL(cutout_factor=0.25),\n",
    "            RandAugment(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        ])\n",
    "        test_transform = transforms.Compose([\n",
    "            # transforms.CenterCrop(img_size),\n",
    "            transforms.Resize((img_size, img_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        ])\n",
    "\n",
    "        if self.data_split == 'trainval':\n",
    "            self.transform = train_transform\n",
    "        elif self.data_split == 'test':\n",
    "            self.transform = test_transform\n",
    "        else:\n",
    "            raise ValueError('data split = %s is not supported in Nus Wide' % self.data_split)\n",
    "\n",
    "        # create the label mask\n",
    "        self.mask = None\n",
    "        self.partial = partial\n",
    "        if data_split == 'trainval' and partial < 1.:\n",
    "            if label_mask is None:\n",
    "                rand_tensor = torch.rand(len(self.image_list), len(self.classnames))\n",
    "                mask = (rand_tensor < partial).long()\n",
    "                mask = torch.stack([mask], dim=1)\n",
    "                torch.save(mask, os.path.join(self.root, 'Annotations', 'partial_label_%.2f.pt' % partial))\n",
    "            else:\n",
    "                mask = torch.load(os.path.join(self.root, 'Annotations', label_mask))\n",
    "            self.mask = mask.long()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.data_split == 'trainval':\n",
    "                si = self.data_split[:-3]\n",
    "        else:\n",
    "            si = self.data_split\n",
    "        \n",
    "        img_path = os.path.join('/home/samyakr2/food/FoodSeg103', 'Images/img_dir/', si+'/', self.image_list[index])\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        label_vector = self.labels_lab[self.image_list[index][:-4]]      \n",
    "        targets = label_vector[1:].long()\n",
    "        target = targets[None, ]\n",
    "        if self.mask is not None:\n",
    "            masked = - torch.ones((1, len(self.classnames)), dtype=torch.long)\n",
    "            target = self.mask[index] * target + (1 - self.mask[index]) * masked\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def name(self):\n",
    "        return 'foodseg103'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72452b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = foodseg103(root = '', data_split = 'trainval', img_size = 224,\n",
    "                                         p=1, annFile='',\n",
    "                                         label_mask=None,\n",
    "                                         partial=1)\n",
    "\n",
    "test_data = foodseg103(root = '', data_split = 'test', img_size = 224,\n",
    "                                         p=1, annFile='',\n",
    "                                         label_mask=None,\n",
    "                                         partial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eb639e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_file = os.path.join('/home/samyakr2/food/FoodSeg103', 'ImageSets', 'trainval.txt')\n",
    "# image_list_file = os.path.join('/home/samyakr2/food/FoodSeg103', 'ImageSets', '%s.txt' % data_split)\n",
    "\n",
    "image_list = []\n",
    "with open(image_list_file) as f:\n",
    "    image_list = f.readlines()\n",
    "image_list = [a.strip() for a in image_list]\n",
    "\n",
    "labels_lab = np.load('/home/samyakr2/food/FoodSeg103/train_labels.npy', allow_pickle=True).item()\n",
    "labels_lab_val = np.load('/home/samyakr2/food/FoodSeg103/test_labels.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebdb6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([104])\n",
      "torch.Size([103])\n"
     ]
    }
   ],
   "source": [
    "for val in labels_lab.values():\n",
    "    print(val.shape)\n",
    "    print(val[1:].shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d911952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # for val in labels_lab.values():\n",
    "\n",
    "# # # Initialize co-occurrence matrix\n",
    "# num_labels = 103\n",
    "# co_occurrence_matrix = np.zeros((num_labels, num_labels))\n",
    "\n",
    "# # Loop over each multi-label vector\n",
    "# for vector in labels_lab_val.values():\n",
    "#     vector_no_background = vector[1:]\n",
    "#     # Iterate over pairs of labels\n",
    "#     for i in range(num_labels):\n",
    "#         for j in range(i, num_labels):\n",
    "#             # If both labels co-occur in this vector, update the co-occurrence matrix\n",
    "#             if vector_no_background[i] == 1 and vector_no_background[j] == 1:\n",
    "#                 co_occurrence_matrix[i, j] += 1\n",
    "#                 co_occurrence_matrix[j, i] += 1  # Since it's symmetric\n",
    "\n",
    "# # Print or use the co-occurrence matrix as needed\n",
    "# print(co_occurrence_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70cd414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# co_occurrence_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b97a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows, cols = co_occurrence_matrix.shape\n",
    "\n",
    "# # Iterate over the diagonal elements and divide them by 2\n",
    "# for i in range(min(rows, cols)):\n",
    "#     co_occurrence_matrix[i, i] /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd4404a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,   0.,   0.,   1.,   2.,   1.,   0.,   1.,   0.,   2.],\n",
       "       [  0.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,  78.,   0.,   0.,   0.,   0.,  14.,  11.,   0.],\n",
       "       [  1.,   0.,   0.,  18.,   3.,   0.,   0.,   3.,   0.,   8.],\n",
       "       [  2.,   0.,   0.,   3.,  77.,   0.,   0.,  17.,   6.,   1.],\n",
       "       [  1.,   0.,   0.,   0.,   0.,   4.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.],\n",
       "       [  1.,   0.,  14.,   3.,  17.,   0.,   0., 277.,  10.,  26.],\n",
       "       [  0.,   0.,  11.,   0.,   6.,   0.,   0.,  10., 120.,   2.],\n",
       "       [  2.,   0.,   0.,   8.,   1.,   0.,   0.,  26.,   2., 126.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_matrix_test[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "02af4578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.,   0.,   0.,   1.,   9.,   3.,   0.,   0.,   2.,   3.],\n",
       "       [  0.,   3.,   0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.],\n",
       "       [  0.,   0., 166.,   0.,   5.,   1.,   0.,  21.,  16.,   0.],\n",
       "       [  1.,   0.,   0.,  49.,   9.,   1.,   0.,  15.,   0.,  18.],\n",
       "       [  9.,   1.,   5.,   9., 218.,   3.,   0.,  47.,  14.,   3.],\n",
       "       [  3.,   0.,   1.,   1.,   3.,  10.,   0.,   1.,   0.,   0.],\n",
       "       [  0.,   0.,   0.,   0.,   0.,   0.,   4.,   0.,   0.,   0.],\n",
       "       [  0.,   0.,  21.,  15.,  47.,   1.,   0., 636.,  18.,  82.],\n",
       "       [  2.,   0.,  16.,   0.,  14.,   0.,   0.,  18., 276.,  13.],\n",
       "       [  3.,   0.,   0.,  18.,   3.,   0.,   0.,  82.,  13., 333.]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_matrix_train = np.load('/home/samyakr2/SHOP/co_occurrence_matrix.npy')\n",
    "co_occurrence_matrix_train[:10, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "56674333",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/samyakr2/SHOP/co_occurrence_matrix_val.npy', co_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7e98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Load the co-occurrence matrix\n",
    "# co_occurrence_matrix = np.load('/home/samyakr2/SHOP/co_occurrence_matrix.npy')\n",
    "\n",
    "# # Get the diagonal values of the matrix\n",
    "# diagonal_values = np.diag(co_occurrence_matrix)\n",
    "\n",
    "# # Divide each row by its corresponding diagonal value\n",
    "# normalized_co_occurrence_matrix = co_occurrence_matrix / diagonal_values[:, None]\n",
    "\n",
    "# # Print or use the normalized co-occurrence matrix as needed\n",
    "# print(normalized_co_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90a2b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/home/samyakr2/SHOP/normalized_foodseg103_co_occurrence_matrix.npy', normalized_co_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a68ed721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0,\n",
       " 1: 21,\n",
       " 2: 3,\n",
       " 3: 166,\n",
       " 4: 49,\n",
       " 5: 218,\n",
       " 6: 10,\n",
       " 7: 4,\n",
       " 8: 636,\n",
       " 9: 276,\n",
       " 10: 333,\n",
       " 11: 96,\n",
       " 12: 80,\n",
       " 13: 127,\n",
       " 14: 129,\n",
       " 15: 45,\n",
       " 16: 24,\n",
       " 17: 70,\n",
       " 18: 20,\n",
       " 19: 13,\n",
       " 20: 18,\n",
       " 21: 32,\n",
       " 22: 41,\n",
       " 23: 7,\n",
       " 24: 223,\n",
       " 25: 106,\n",
       " 26: 7,\n",
       " 27: 22,\n",
       " 28: 57,\n",
       " 29: 100,\n",
       " 30: 388,\n",
       " 31: 159,\n",
       " 32: 152,\n",
       " 33: 47,\n",
       " 34: 43,\n",
       " 35: 43,\n",
       " 36: 73,\n",
       " 37: 423,\n",
       " 38: 30,\n",
       " 39: 21,\n",
       " 40: 94,\n",
       " 41: 123,\n",
       " 42: 38,\n",
       " 43: 20,\n",
       " 44: 183,\n",
       " 45: 29,\n",
       " 46: 728,\n",
       " 47: 474,\n",
       " 48: 848,\n",
       " 49: 195,\n",
       " 50: 154,\n",
       " 51: 71,\n",
       " 52: 818,\n",
       " 53: 14,\n",
       " 54: 258,\n",
       " 55: 30,\n",
       " 56: 99,\n",
       " 57: 67,\n",
       " 58: 991,\n",
       " 59: 343,\n",
       " 60: 5,\n",
       " 61: 54,\n",
       " 62: 19,\n",
       " 63: 9,\n",
       " 64: 114,\n",
       " 65: 187,\n",
       " 66: 464,\n",
       " 67: 397,\n",
       " 68: 48,\n",
       " 69: 19,\n",
       " 70: 785,\n",
       " 71: 73,\n",
       " 72: 157,\n",
       " 73: 790,\n",
       " 74: 1,\n",
       " 75: 7,\n",
       " 76: 133,\n",
       " 77: 54,\n",
       " 78: 23,\n",
       " 79: 15,\n",
       " 80: 403,\n",
       " 81: 72,\n",
       " 82: 369,\n",
       " 83: 36,\n",
       " 84: 881,\n",
       " 85: 187,\n",
       " 86: 3,\n",
       " 87: 704,\n",
       " 88: 164,\n",
       " 89: 636,\n",
       " 90: 48,\n",
       " 91: 94,\n",
       " 92: 24,\n",
       " 93: 374,\n",
       " 94: 305,\n",
       " 95: 152,\n",
       " 96: 253,\n",
       " 97: 10,\n",
       " 98: 82,\n",
       " 99: 6,\n",
       " 100: 7,\n",
       " 101: 99,\n",
       " 102: 12,\n",
       " 103: 155}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_counts = {i: 0 for i in range(104)}\n",
    "\n",
    "for file in image_list:\n",
    "    key = file[:-4]  # Extract the key from the filename\n",
    "    if key in labels_lab:  # Check if the key exists in the labels_lab dictionary\n",
    "        label_tensor = labels_lab[key]\n",
    "        indices_gt_zero = torch.nonzero(label_tensor > 0).squeeze()\n",
    "        if indices_gt_zero.dim() == 0:\n",
    "            indices_gt_zero = indices_gt_zero.unsqueeze(0)\n",
    "        for index in indices_gt_zero:\n",
    "            index_counts[index.item()] += 1\n",
    "index_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4fc9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=32,\n",
    "                                             shuffle=True,\n",
    "                                             num_workers=3, pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100,\n",
    "                                             shuffle=False,\n",
    "                                             num_workers=3, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b416e750",
   "metadata": {},
   "source": [
    "## MODEL PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb38de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import copy\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0730f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(clip.available_models())\n",
    "clip_model, preprocess = clip.load('RN101', device)\n",
    "clip_model = clip_model#.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce026648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([103, 103])\n"
     ]
    }
   ],
   "source": [
    "# labels_food = [\"candy\", \"egg tart\", \"french fries\", \"chocolate\", \"biscuit\", \"popcorn\", \"pudding\", \"ice cream\", \"cheese butter\", \"cake\", \"wine\", \"milkshake\", \"coffee\", \"juice\", \"milk\", \"tea\", \"almond\", \"red beans\", \"cashew\", \"dried cranberries\", \"soy\", \"walnut\", \"peanut\", \"egg\", \"apple\", \"date\", \"apricot\", \"avocado\", \"banana\", \"strawberry\", \"cherry\", \"blueberry\", \"raspberry\", \"mango\", \"olives\", \"peach\", \"lemon\", \"pear\", \"fig\", \"pineapple\", \"grape\", \"kiwi\", \"melon\", \"orange\", \"watermelon\", \"steak\", \"pork\", \"chicken duck\", \"sausage\", \"fried meat\", \"lamb\", \"sauce\", \"crab\", \"fish\", \"shellfish\", \"shrimp\", \"soup\", \"bread\", \"corn\", \"hamburg\", \"pizza\", \"hanamaki baozi\", \"wonton dumplings\", \"pasta\", \"noodles\", \"rice\", \"pie\", \"tofu\", \"eggplant\", \"potato\", \"garlic\", \"cauliflower\", \"tomato\", \"kelp\", \"seaweed\", \"spring onion\", \"rape\", \"ginger\", \"okra\", \"lettuce\", \"pumpkin\", \"cucumber\", \"white radish\", \"carrot\", \"asparagus\", \"bamboo shoots\", \"broccoli\", \"celery stick\", \"cilantro mint\", \"snow peas\", \"cabbage\", \"bean sprouts\", \"onion\", \"pepper\", \"green beans\", \"French beans\", \"king oyster mushroom\", \"shiitake\", \"enoki mushroom\", \"oyster mushroom\", \"white button mushroom\", \"salad\", \"other ingredients\"]\n",
    "\n",
    "# items_food = [\"A photo of a \" + item + ', a type of food' for item in labels_food]\n",
    "\n",
    "# text = clip.tokenize(items_food).to(device)\n",
    "# text_features = clip_model.encode_text(text)\n",
    "# text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "# text_features_path = '/home/samyakr2/SHOP/foodseg103_labels.pt'\n",
    "# torch.save(text_features, text_features_path)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "text_features_path = '/home/samyakr2/SHOP/foodseg103_labels.pt'\n",
    "text_features = torch.load(text_features_path).to(torch.float32)\n",
    "similarity_text = (text_features @ text_features.T)\n",
    "print(similarity_text.shape)\n",
    "torch.save(similarity_text, '/home/samyakr2/SHOP/foodseg103_relation.pt')\n",
    "np.save('/home/samyakr2/SHOP/foodseg103_relation.npy', similarity_text.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcb1112f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 80])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load('/home/samyakr2/SHOP/relation+coco.npy')\n",
    "a.shape\n",
    "\n",
    "relation = torch.Tensor(a)\n",
    "        \n",
    "_ ,max_idx = torch.topk(relation, 50)\n",
    "mask = torch.ones_like(relation).type(torch.bool)\n",
    "for i, idx in enumerate(max_idx):\n",
    "    mask[i][idx] = 0\n",
    "relation[mask] = 0\n",
    "sparse_mask = mask\n",
    "dialog = torch.eye(80).type(torch.bool)\n",
    "relation[dialog] = 0\n",
    "relation = relation / torch.sum(relation, dim=1).reshape(-1, 1) * 0.2\n",
    "relation[dialog] = 1-0.2\n",
    "\n",
    "gcn_relation = relation.clone()\n",
    "gcn_relation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dab3cb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_features(dataloader):\n",
    "    all_features_batches = []\n",
    "    all_labels_batches = []\n",
    "    for images, labels in dataloader:\n",
    "        features = clip_model.encode_image(images.to(device))\n",
    "        all_features_batches.append(features.detach())\n",
    "        all_labels_batches.append(labels)\n",
    "    return all_features_batches, all_labels_batches\n",
    "\n",
    "# train_features, train_labels = get_features(train_loader)\n",
    "# val_features, val_labels = get_features(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b691ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features_path = '/home/samyakr2/SHOP/foodseg103_train_img.pt'\n",
    "# torch.save(train_features, train_features_path)\n",
    "\n",
    "# train_labels_path = '/home/samyakr2/SHOP/foodseg103_train_label.pt'\n",
    "# torch.save(train_labels, train_labels_path)\n",
    "\n",
    "# val_features_path = '/home/samyakr2/SHOP/foodseg103_test_img.pt'\n",
    "# torch.save(val_features, val_features_path)\n",
    "\n",
    "# val_labels_path = '/home/samyakr2/SHOP/foodseg103_test_label.pt'\n",
    "# torch.save(val_labels, val_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f9cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_path = '/home/samyakr2/SHOP/foodseg103_train_img.pt'\n",
    "train_features = torch.load(train_features_path)\n",
    "\n",
    "train_labels_path = '/home/samyakr2/SHOP/foodseg103_train_label.pt'\n",
    "train_labels = torch.load(train_labels_path)\n",
    "\n",
    "val_features_path = '/home/samyakr2/SHOP/foodseg103_test_img.pt'\n",
    "val_features = torch.load(val_features_path)\n",
    "\n",
    "val_labels_path = '/home/samyakr2/SHOP/foodseg103_test_label.pt'\n",
    "val_labels = torch.load(val_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9faf5aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7001b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clip_2fc(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(clip_2fc, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim,bias=False)\n",
    "        )\n",
    "        \n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim),\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc2(out)\n",
    "#         out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2ace174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsymmetricLoss(nn.Module):\n",
    "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-6, disable_torch_grad_focal_loss=True):\n",
    "        super(AsymmetricLoss, self).__init__()\n",
    "\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.clip = clip\n",
    "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
    "        self.eps = eps\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: input logits\n",
    "        y: targets (multi-label binarized vector)\n",
    "        \"\"\"\n",
    "        # Calculating Probabilities\n",
    "        x_sigmoid = torch.sigmoid(x)\n",
    "        xs_pos = x_sigmoid\n",
    "        xs_neg = 1 - x_sigmoid\n",
    "        \n",
    "        \n",
    "#         print('X.shape', x.shape)\n",
    "#         print('Y shape',y.shape)\n",
    "#         x_softmax = self.softmax(x)\n",
    "#         print()\n",
    "#         xs_pos = x_softmax[:, 1, :]\n",
    "#         xs_neg = x_softmax[:, 0, :]\n",
    "#         y = y.reshape(-1)\n",
    "#         xs_pos = xs_pos.reshape(-1)\n",
    "#         xs_neg = xs_neg.reshape(-1)\n",
    "\n",
    "#         xs_pos = xs_pos[y!=-1]\n",
    "#         xs_neg = xs_neg[y!=-1]\n",
    "#         y = y[y!=-1]\n",
    "\n",
    "        # Asymmetric Clipping\n",
    "        if self.clip is not None and self.clip > 0:\n",
    "            xs_neg = (xs_neg + self.clip).clamp(max=1)\n",
    "\n",
    "        # Basic CE calculation\n",
    "        los_pos = y * torch.log(xs_pos.clamp(min=self.eps))\n",
    "        los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))\n",
    "        loss = los_pos + los_neg\n",
    "\n",
    "\n",
    "        # Asymmetric Focusing\n",
    "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(False)\n",
    "            pt0 = xs_pos * y\n",
    "            pt1 = xs_neg * (1 - y)  # pt = p if t > 0 else 1-p\n",
    "            pt = pt0 + pt1\n",
    "            one_sided_gamma = self.gamma_pos * y + self.gamma_neg * (1 - y)\n",
    "            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(True)\n",
    "            loss *= one_sided_w\n",
    "\n",
    "        return -loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a89bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "\n",
    "input_size = train_features[0].size(1)  \n",
    "hidden_size = 200\n",
    "num_classes = 103 # len(labels_food)\n",
    "model = clip_2fc(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "lr = 0.002\n",
    "max_epochs = 50\n",
    "warmup_epochs = 1\n",
    "warmup_constant_lr = 1e-5\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=warmup_epochs, T_mult=1, eta_min=warmup_constant_lr)\n",
    "\n",
    "criterion = AsymmetricLoss(2, 1) # Y_neg = 2, Y_pos = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cde27548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/250], Loss: 66155.56857299805\n",
      "Epoch [2/250], Loss: 66150.37854003906\n",
      "Epoch [3/250], Loss: 66135.43002319336\n",
      "Epoch [4/250], Loss: 66123.06134033203\n",
      "Epoch [5/250], Loss: 66112.13363647461\n",
      "Epoch [6/250], Loss: 66102.05670166016\n",
      "Epoch [7/250], Loss: 66092.50286865234\n",
      "Epoch [8/250], Loss: 66083.2783203125\n",
      "Epoch [9/250], Loss: 66074.26190185547\n",
      "Epoch [10/250], Loss: 66065.3734741211\n",
      "Epoch [11/250], Loss: 66056.55975341797\n",
      "Epoch [12/250], Loss: 66047.78259277344\n",
      "Epoch [13/250], Loss: 66039.01550292969\n",
      "Epoch [14/250], Loss: 66030.23910522461\n",
      "Epoch [15/250], Loss: 66021.43859863281\n",
      "Epoch [16/250], Loss: 66012.60360717773\n",
      "Epoch [17/250], Loss: 66003.72546386719\n",
      "Epoch [18/250], Loss: 65994.7984008789\n",
      "Epoch [19/250], Loss: 65985.81677246094\n",
      "Epoch [20/250], Loss: 65976.77853393555\n",
      "Epoch [21/250], Loss: 65967.67904663086\n",
      "Epoch [22/250], Loss: 65958.51742553711\n",
      "Epoch [23/250], Loss: 65949.29098510742\n",
      "Epoch [24/250], Loss: 65939.9994506836\n",
      "Epoch [25/250], Loss: 65930.64126586914\n",
      "Epoch [26/250], Loss: 65921.21597290039\n",
      "Epoch [27/250], Loss: 65911.7229309082\n",
      "Epoch [28/250], Loss: 65902.16213989258\n",
      "Epoch [29/250], Loss: 65892.53305053711\n",
      "Epoch [30/250], Loss: 65882.83590698242\n",
      "Epoch [31/250], Loss: 65873.07095336914\n",
      "Epoch [32/250], Loss: 65863.23767089844\n",
      "Epoch [33/250], Loss: 65853.33682250977\n",
      "Epoch [34/250], Loss: 65843.36834716797\n",
      "Epoch [35/250], Loss: 65833.3327331543\n",
      "Epoch [36/250], Loss: 65823.22979736328\n",
      "Epoch [37/250], Loss: 65813.06060791016\n",
      "Epoch [38/250], Loss: 65802.82559204102\n",
      "Epoch [39/250], Loss: 65792.52368164062\n",
      "Epoch [40/250], Loss: 65782.15682983398\n",
      "Epoch [41/250], Loss: 65771.72448730469\n",
      "Epoch [42/250], Loss: 65761.22766113281\n",
      "Epoch [43/250], Loss: 65750.66613769531\n",
      "Epoch [44/250], Loss: 65740.04077148438\n",
      "Epoch [45/250], Loss: 65729.35241699219\n",
      "Epoch [46/250], Loss: 65718.60095214844\n",
      "Epoch [47/250], Loss: 65707.7865600586\n",
      "Epoch [48/250], Loss: 65696.9097290039\n",
      "Epoch [49/250], Loss: 65685.9714050293\n",
      "Epoch [50/250], Loss: 65674.97198486328\n",
      "Epoch [51/250], Loss: 65663.91162109375\n",
      "Epoch [52/250], Loss: 65652.79022216797\n",
      "Epoch [53/250], Loss: 65641.60916137695\n",
      "Epoch [54/250], Loss: 65630.36831665039\n",
      "Epoch [55/250], Loss: 65619.068359375\n",
      "Epoch [56/250], Loss: 65607.70932006836\n",
      "Epoch [57/250], Loss: 65596.29220581055\n",
      "Epoch [58/250], Loss: 65584.81692504883\n",
      "Epoch [59/250], Loss: 65573.2839050293\n",
      "Epoch [60/250], Loss: 65561.69409179688\n",
      "Epoch [61/250], Loss: 65550.04666137695\n",
      "Epoch [62/250], Loss: 65538.34368896484\n",
      "Epoch [63/250], Loss: 65526.58386230469\n",
      "Epoch [64/250], Loss: 65514.768798828125\n",
      "Epoch [65/250], Loss: 65502.89810180664\n",
      "Epoch [66/250], Loss: 65490.97283935547\n",
      "Epoch [67/250], Loss: 65478.993103027344\n",
      "Epoch [68/250], Loss: 65466.95880126953\n",
      "Epoch [69/250], Loss: 65454.87088012695\n",
      "Epoch [70/250], Loss: 65442.729248046875\n",
      "Epoch [71/250], Loss: 65430.53421020508\n",
      "Epoch [72/250], Loss: 65418.287109375\n",
      "Epoch [73/250], Loss: 65405.98776245117\n",
      "Epoch [74/250], Loss: 65393.63571166992\n",
      "Epoch [75/250], Loss: 65381.232177734375\n",
      "Epoch [76/250], Loss: 65368.77700805664\n",
      "Epoch [77/250], Loss: 65356.27096557617\n",
      "Epoch [78/250], Loss: 65343.7145690918\n",
      "Epoch [79/250], Loss: 65331.107421875\n",
      "Epoch [80/250], Loss: 65318.449951171875\n",
      "Epoch [81/250], Loss: 65305.74301147461\n",
      "Epoch [82/250], Loss: 65292.986877441406\n",
      "Epoch [83/250], Loss: 65280.18133544922\n",
      "Epoch [84/250], Loss: 65267.32696533203\n",
      "Epoch [85/250], Loss: 65254.423736572266\n",
      "Epoch [86/250], Loss: 65241.472564697266\n",
      "Epoch [87/250], Loss: 65228.47381591797\n",
      "Epoch [88/250], Loss: 65215.42663574219\n",
      "Epoch [89/250], Loss: 65202.3330078125\n",
      "Epoch [90/250], Loss: 65189.19171142578\n",
      "Epoch [91/250], Loss: 65176.003997802734\n",
      "Epoch [92/250], Loss: 65162.769775390625\n",
      "Epoch [93/250], Loss: 65149.48889160156\n",
      "Epoch [94/250], Loss: 65136.1623840332\n",
      "Epoch [95/250], Loss: 65122.79064941406\n",
      "Epoch [96/250], Loss: 65109.37322998047\n",
      "Epoch [97/250], Loss: 65095.91049194336\n",
      "Epoch [98/250], Loss: 65082.40295410156\n",
      "Epoch [99/250], Loss: 65068.85043334961\n",
      "Epoch [100/250], Loss: 65055.25424194336\n",
      "Epoch [101/250], Loss: 65041.61404418945\n",
      "Epoch [102/250], Loss: 65027.928955078125\n",
      "Epoch [103/250], Loss: 65014.20101928711\n",
      "Epoch [104/250], Loss: 65000.429779052734\n",
      "Epoch [105/250], Loss: 64986.61572265625\n",
      "Epoch [106/250], Loss: 64972.75848388672\n",
      "Epoch [107/250], Loss: 64958.858795166016\n",
      "Epoch [108/250], Loss: 64944.91680908203\n",
      "Epoch [109/250], Loss: 64930.932556152344\n",
      "Epoch [110/250], Loss: 64916.90661621094\n",
      "Epoch [111/250], Loss: 64902.839263916016\n",
      "Epoch [112/250], Loss: 64888.72982788086\n",
      "Epoch [113/250], Loss: 64874.579986572266\n",
      "Epoch [114/250], Loss: 64860.38943481445\n",
      "Epoch [115/250], Loss: 64846.157287597656\n",
      "Epoch [116/250], Loss: 64831.885009765625\n",
      "Epoch [117/250], Loss: 64817.57278442383\n",
      "Epoch [118/250], Loss: 64803.220153808594\n",
      "Epoch [119/250], Loss: 64788.82815551758\n",
      "Epoch [120/250], Loss: 64774.39596557617\n",
      "Epoch [121/250], Loss: 64759.9248046875\n",
      "Epoch [122/250], Loss: 64745.41442871094\n",
      "Epoch [123/250], Loss: 64730.86520385742\n",
      "Epoch [124/250], Loss: 64716.2770690918\n",
      "Epoch [125/250], Loss: 64701.65057373047\n",
      "Epoch [126/250], Loss: 64686.98556518555\n",
      "Epoch [127/250], Loss: 64672.2825012207\n",
      "Epoch [128/250], Loss: 64657.541595458984\n",
      "Epoch [129/250], Loss: 64642.76321411133\n",
      "Epoch [130/250], Loss: 64627.94677734375\n",
      "Epoch [131/250], Loss: 64613.09344482422\n",
      "Epoch [132/250], Loss: 64598.20275878906\n",
      "Epoch [133/250], Loss: 64583.274993896484\n",
      "Epoch [134/250], Loss: 64568.31051635742\n",
      "Epoch [135/250], Loss: 64553.309814453125\n",
      "Epoch [136/250], Loss: 64538.27243041992\n",
      "Epoch [137/250], Loss: 64523.198974609375\n",
      "Epoch [138/250], Loss: 64508.08953857422\n",
      "Epoch [139/250], Loss: 64492.94421386719\n",
      "Epoch [140/250], Loss: 64477.76385498047\n",
      "Epoch [141/250], Loss: 64462.547424316406\n",
      "Epoch [142/250], Loss: 64447.295989990234\n",
      "Epoch [143/250], Loss: 64432.0094909668\n",
      "Epoch [144/250], Loss: 64416.68826293945\n",
      "Epoch [145/250], Loss: 64401.33203125\n",
      "Epoch [146/250], Loss: 64385.94137573242\n",
      "Epoch [147/250], Loss: 64370.51623535156\n",
      "Epoch [148/250], Loss: 64355.05697631836\n",
      "Epoch [149/250], Loss: 64339.56378173828\n",
      "Epoch [150/250], Loss: 64324.03646850586\n",
      "Epoch [151/250], Loss: 64308.47576904297\n",
      "Epoch [152/250], Loss: 64292.881439208984\n",
      "Epoch [153/250], Loss: 64277.25372314453\n",
      "Epoch [154/250], Loss: 64261.592681884766\n",
      "Epoch [155/250], Loss: 64245.8991394043\n",
      "Epoch [156/250], Loss: 64230.17239379883\n",
      "Epoch [157/250], Loss: 64214.41320800781\n",
      "Epoch [158/250], Loss: 64198.62109375\n",
      "Epoch [159/250], Loss: 64182.796325683594\n",
      "Epoch [160/250], Loss: 64166.94039916992\n",
      "Epoch [161/250], Loss: 64151.05163574219\n",
      "Epoch [162/250], Loss: 64135.13104248047\n",
      "Epoch [163/250], Loss: 64119.17886352539\n",
      "Epoch [164/250], Loss: 64103.19512939453\n",
      "Epoch [165/250], Loss: 64087.1799621582\n",
      "Epoch [166/250], Loss: 64071.13311767578\n",
      "Epoch [167/250], Loss: 64055.05563354492\n",
      "Epoch [168/250], Loss: 64038.9465637207\n",
      "Epoch [169/250], Loss: 64022.80700683594\n",
      "Epoch [170/250], Loss: 64006.636962890625\n",
      "Epoch [171/250], Loss: 63990.43615722656\n",
      "Epoch [172/250], Loss: 63974.20492553711\n",
      "Epoch [173/250], Loss: 63957.943267822266\n",
      "Epoch [174/250], Loss: 63941.65167236328\n",
      "Epoch [175/250], Loss: 63925.330169677734\n",
      "Epoch [176/250], Loss: 63908.97900390625\n",
      "Epoch [177/250], Loss: 63892.59750366211\n",
      "Epoch [178/250], Loss: 63876.187255859375\n",
      "Epoch [179/250], Loss: 63859.74728393555\n",
      "Epoch [180/250], Loss: 63843.2780456543\n",
      "Epoch [181/250], Loss: 63826.77963256836\n",
      "Epoch [182/250], Loss: 63810.25274658203\n",
      "Epoch [183/250], Loss: 63793.6960144043\n",
      "Epoch [184/250], Loss: 63777.11080932617\n",
      "Epoch [185/250], Loss: 63760.49737548828\n",
      "Epoch [186/250], Loss: 63743.85528564453\n",
      "Epoch [187/250], Loss: 63727.18539428711\n",
      "Epoch [188/250], Loss: 63710.48681640625\n",
      "Epoch [189/250], Loss: 63693.760009765625\n",
      "Epoch [190/250], Loss: 63677.00564575195\n",
      "Epoch [191/250], Loss: 63660.22344970703\n",
      "Epoch [192/250], Loss: 63643.41320800781\n",
      "Epoch [193/250], Loss: 63626.575622558594\n",
      "Epoch [194/250], Loss: 63609.711029052734\n",
      "Epoch [195/250], Loss: 63592.818603515625\n",
      "Epoch [196/250], Loss: 63575.89938354492\n",
      "Epoch [197/250], Loss: 63558.952728271484\n",
      "Epoch [198/250], Loss: 63541.97927856445\n",
      "Epoch [199/250], Loss: 63524.97970581055\n",
      "Epoch [200/250], Loss: 63507.9528503418\n",
      "Epoch [201/250], Loss: 63490.89923095703\n",
      "Epoch [202/250], Loss: 63473.819732666016\n",
      "Epoch [203/250], Loss: 63456.71340942383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [204/250], Loss: 63439.58142089844\n",
      "Epoch [205/250], Loss: 63422.423400878906\n",
      "Epoch [206/250], Loss: 63405.23944091797\n",
      "Epoch [207/250], Loss: 63388.02951049805\n",
      "Epoch [208/250], Loss: 63370.79364013672\n",
      "Epoch [209/250], Loss: 63353.53286743164\n",
      "Epoch [210/250], Loss: 63336.24639892578\n",
      "Epoch [211/250], Loss: 63318.93444824219\n",
      "Epoch [212/250], Loss: 63301.597229003906\n",
      "Epoch [213/250], Loss: 63284.23501586914\n",
      "Epoch [214/250], Loss: 63266.84811401367\n",
      "Epoch [215/250], Loss: 63249.43566894531\n",
      "Epoch [216/250], Loss: 63231.99899291992\n",
      "Epoch [217/250], Loss: 63214.5373840332\n",
      "Epoch [218/250], Loss: 63197.051330566406\n",
      "Epoch [219/250], Loss: 63179.541595458984\n",
      "Epoch [220/250], Loss: 63162.0075378418\n",
      "Epoch [221/250], Loss: 63144.44869995117\n",
      "Epoch [222/250], Loss: 63126.86633300781\n",
      "Epoch [223/250], Loss: 63109.25988769531\n",
      "Epoch [224/250], Loss: 63091.62857055664\n",
      "Epoch [225/250], Loss: 63073.97393798828\n",
      "Epoch [226/250], Loss: 63056.296295166016\n",
      "Epoch [227/250], Loss: 63038.59469604492\n",
      "Epoch [228/250], Loss: 63020.8701171875\n",
      "Epoch [229/250], Loss: 63003.12161254883\n",
      "Epoch [230/250], Loss: 62985.350036621094\n",
      "Epoch [231/250], Loss: 62967.55545043945\n",
      "Epoch [232/250], Loss: 62949.73812866211\n",
      "Epoch [233/250], Loss: 62931.89749145508\n",
      "Epoch [234/250], Loss: 62914.03436279297\n",
      "Epoch [235/250], Loss: 62896.14807128906\n",
      "Epoch [236/250], Loss: 62878.2399597168\n",
      "Epoch [237/250], Loss: 62860.30953979492\n",
      "Epoch [238/250], Loss: 62842.35568237305\n",
      "Epoch [239/250], Loss: 62824.38064575195\n",
      "Epoch [240/250], Loss: 62806.38262939453\n",
      "Epoch [241/250], Loss: 62788.36282348633\n",
      "Epoch [242/250], Loss: 62770.321380615234\n",
      "Epoch [243/250], Loss: 62752.258056640625\n",
      "Epoch [244/250], Loss: 62734.17218017578\n",
      "Epoch [245/250], Loss: 62716.0651550293\n",
      "Epoch [246/250], Loss: 62697.93704223633\n",
      "Epoch [247/250], Loss: 62679.787109375\n",
      "Epoch [248/250], Loss: 62661.615478515625\n",
      "Epoch [249/250], Loss: 62643.42306518555\n",
      "Epoch [250/250], Loss: 62625.20980834961\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 250\n",
    "len_labels = 103\n",
    "\n",
    "\n",
    "gamma = torch.ones(len_labels) / len_labels\n",
    "gamma = gamma.to(device)\n",
    "\n",
    "alpha = np.zeros(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    for features_batch, labels_batch in zip(train_features, train_labels):\n",
    "        # Flatten features batch\n",
    "        \n",
    "    \n",
    "        features_batch = features_batch.view(features_batch.size(0), -1).to(torch.float32)\n",
    "        gamma = gamma.detach()\n",
    "        \n",
    "        # Convert labels to tensor\n",
    "        labels_tensor = labels_batch.type(torch.float32).to(device)#torch.tensor(labels_batch, dtype=torch.float32)#\n",
    "        labels_tensor = labels_tensor.squeeze(dim=1)\n",
    "        # Forward pass\n",
    "        outputs = model(features_batch.to(device))\n",
    "        similarity_text = (text_features @ text_features.T)\n",
    "        normalized_similarity_text = F.normalize(similarity_text, p=2, dim=1)  # Normalize along the second dimension (rows)\n",
    "        \n",
    "        normalized_similarity_text = torch.clamp(normalized_similarity_text, min=0, max=1)  # Clamp values to be between 0 and 1\n",
    "        normalized_similarity_with_gamma = normalized_similarity_text * gamma\n",
    "\n",
    "        outputs_reshaped = outputs.unsqueeze(1)\n",
    "        \n",
    "        result = torch.sum(outputs_reshaped * normalized_similarity_with_gamma.unsqueeze(0), dim =2)\n",
    "        pred = result\n",
    "        \n",
    "        \n",
    "        \n",
    "#         labels_tensor_gamma = labels_tensor * 2 - 1\n",
    "        r = torch.sum(gamma * labels_tensor * torch.sigmoid(pred))#/len(label_tensor_gamma)\n",
    "#         r = torch.sum(gamma * labels_tensor_gamma * torch.tanh(pred)) / len(label_tensor_gamma)\n",
    "        \n",
    "#         print(r)\n",
    "#         print('-'*25)\n",
    "        \n",
    "        a = 0.5 * torch.log((1 + r) / (1 - r))\n",
    "\n",
    "        gamma = gamma * torch.exp(-a * labels_tensor * torch.sigmoid(pred))\n",
    "#         gamma = gamma * torch.exp(-a * labels_tensor_gamma * torch.tanh(pred))#torch.sigmoid(pred))\n",
    "        sum_val = torch.sum(gamma)\n",
    "        gamma = gamma / sum_val\n",
    "        gamma = torch.min(gamma, dim=0).values\n",
    "        \n",
    "#         print(gamma)\n",
    "#         print('*'*25)\n",
    "        \n",
    "        \n",
    "        loss = criterion(pred, labels_tensor)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "#         print(\"==\"*50)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}\")\n",
    "#     if epoch_loss < best_loss:\n",
    "#         best_loss = epoch_loss\n",
    "#         best_model_state_dict = model.state_dict()\n",
    "        \n",
    "#     if (epoch + 1) % 100 == 0:\n",
    "#         torch.save(best_model_state_dict, f\"/home/samyakr2/food_seg/weights/best_epoch_{epoch+1+5000}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa53f908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision Score: 0.0390861065527771\n",
      "0.04106429523626541\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Define a function for testing the model\n",
    "\n",
    "def average_precision(output, target):\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    # sort examples\n",
    "    indices = output.argsort()[::-1]\n",
    "    # Computes prec@i\n",
    "    total_count_ = np.cumsum(np.ones((len(output), 1)))\n",
    "\n",
    "    target_ = target[indices]\n",
    "    ind = target_ == 1\n",
    "    pos_count_ = np.cumsum(ind)\n",
    "    total = pos_count_[-1]\n",
    "    pos_count_[np.logical_not(ind)] = 0\n",
    "    pp = pos_count_ / total_count_\n",
    "    precision_at_i_ = np.sum(pp)\n",
    "    precision_at_i = precision_at_i_ / (total + epsilon)\n",
    "\n",
    "    return precision_at_i\n",
    "\n",
    "\n",
    "def mAP(targs, preds):\n",
    "    \"\"\"Returns the model's average precision for each class\n",
    "    Return:\n",
    "        ap (FloatTensor): 1xK tensor, with avg precision for each class k\n",
    "    \"\"\"\n",
    "\n",
    "    if np.size(preds) == 0:\n",
    "        return 0\n",
    "    ap = np.zeros((preds.shape[1]))\n",
    "    # compute average precision for each class\n",
    "    for k in range(preds.shape[1]):\n",
    "        # sort scores\n",
    "        scores = preds[:, k]\n",
    "        targets = targs[:, k]\n",
    "        # compute average precision\n",
    "        ap[k] = average_precision(scores, targets)\n",
    "    return ap.mean()\n",
    "\n",
    "def test_model(model,text_features,criterion, features_batches, labels_batches, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for features_batch, labels_batch in zip(features_batches, labels_batches):\n",
    "            # Move batch to device\n",
    "            features_batch = features_batch.to(device).to(torch.float32)\n",
    "            labels_tensor =  labels_batch.type(torch.float32).to(device)#torch.tensor(labels_batch, dtype=torch.float32).to(device)\n",
    "            labels_tensor = labels_tensor.squeeze(dim=1)\n",
    "            # Flatten features batch\n",
    "            features_batch = features_batch.view(features_batch.size(0), -1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features_batch)\n",
    "            similarity_text = (text_features @ text_features.T)\n",
    "            \n",
    "            normalized_similarity_text = F.normalize(similarity_text, p=2, dim=1)\n",
    "            normalized_similarity_text = torch.clamp(normalized_similarity_text, min=0, max=1)  # Clamp values to be between 0 and 1\n",
    "            normalized_similarity_with_gamma = normalized_similarity_text * gamma\n",
    "#           \n",
    "            outputs_reshaped = outputs.unsqueeze(1)\n",
    "            result = torch.sum(outputs_reshaped * normalized_similarity_with_gamma.unsqueeze(0), dim =2)\n",
    "            pred = result\n",
    "        \n",
    "            loss = criterion(pred, labels_tensor)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Convert outputs and labels to numpy arrays\n",
    "            outputs_np = torch.sigmoid(pred).cpu().detach().numpy()\n",
    "            labels_np = labels_tensor.cpu().detach().numpy()\n",
    "\n",
    "            all_outputs.append(outputs_np)\n",
    "            all_labels.append(labels_np)\n",
    "\n",
    "    # Concatenate outputs and labels\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "#     print(all_labels)\n",
    "    # Compute average precision score\n",
    "    avg_precision = average_precision_score(all_labels, all_outputs, average='micro')\n",
    "    answer_to_ = mAP(all_labels, all_outputs)\n",
    "    # Average test loss\n",
    "    avg_test_loss = test_loss / len(features_batches)\n",
    "#     print(f\"Test Loss: {avg_test_loss}\")\n",
    "    print(f\"Average Precision Score: {avg_precision}\")\n",
    "    print(answer_to_)\n",
    "\n",
    "# criterion = nn.BCELoss()  \n",
    "test_model(model, text_features, criterion, val_features, val_labels, device)\n",
    "\n",
    "# for i in range (4900, 4901):\n",
    "#     print(i)\n",
    "#     best_model_state_dict = torch.load(\"/home/samyakr2/food_seg/weights/best_epoch_{}.pth\".format(i))\n",
    "#     model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "#     test_model(model, text_features, criterion, val_features, val_labels, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c9a2fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9715e-04, 5.2011e-03, 2.1730e-09, 1.5006e-05, 6.4267e-11, 1.0832e-03,\n",
       "        3.4567e-03, 3.4142e-13, 8.6322e-12, 6.5685e-12, 3.9179e-07, 5.4561e-07,\n",
       "        6.2882e-09, 7.4810e-09, 4.6902e-06, 2.2173e-04, 2.8009e-06, 2.7194e-04,\n",
       "        6.8238e-04, 6.0110e-04, 1.4515e-04, 1.4466e-05, 2.2478e-03, 1.1130e-10,\n",
       "        7.6886e-08, 2.0788e-03, 3.1588e-04, 2.9790e-06, 4.0096e-08, 8.7602e-13,\n",
       "        2.9217e-09, 5.8194e-09, 1.5598e-05, 1.2778e-05, 5.4028e-05, 2.7427e-06,\n",
       "        1.2055e-12, 6.1414e-05, 2.1950e-04, 6.0362e-08, 6.4709e-09, 2.5571e-05,\n",
       "        1.8665e-04, 7.0709e-10, 1.9597e-04, 2.5266e-13, 3.1833e-13, 3.1732e-13,\n",
       "        3.0857e-10, 1.0982e-09, 3.7097e-07, 2.8054e-13, 9.0279e-04, 1.8956e-11,\n",
       "        1.3256e-04, 8.9791e-08, 3.5011e-06, 2.5095e-13, 3.4066e-12, 2.7109e-03,\n",
       "        2.1469e-06, 3.9705e-04, 1.3815e-03, 1.4227e-08, 1.2180e-10, 8.3105e-13,\n",
       "        2.3588e-12, 6.9830e-06, 4.3593e-04, 2.5264e-13, 3.4759e-07, 5.7132e-09,\n",
       "        2.5071e-13, 6.5412e-03, 2.1085e-03, 1.0981e-08, 4.5325e-06, 1.4510e-04,\n",
       "        9.9366e-04, 1.7874e-12, 1.2470e-06, 1.8093e-12, 4.1201e-05, 2.5188e-13,\n",
       "        4.8257e-10, 3.6686e-03, 3.0690e-13, 4.3872e-10, 2.5188e-13, 1.5597e-05,\n",
       "        2.0036e-07, 1.1583e-04, 1.6493e-12, 9.5077e-12, 1.8424e-09, 1.0992e-11,\n",
       "        1.4705e-03, 6.3478e-07, 2.1651e-03, 2.2720e-03, 6.9122e-08, 6.4173e-04,\n",
       "        1.5491e-09], device='cuda:0', grad_fn=<MinBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca301a8",
   "metadata": {},
   "source": [
    "### Pretraining CLIP with FoodSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7af989a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class clip_2fc(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(clip_2fc, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim,bias=False)\n",
    "        )\n",
    "        \n",
    "#         self.fc1 = nn.Linear(input_dim, hidden_dim),\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "#         out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e362d520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "input_size = train_features[0].size(1)  \n",
    "hidden_size = 256  # Define the size of the hidden layer\n",
    "num_classes = 103 #len(train_labels[0][0])  # Assuming labels_batches is a list of lists of labels\n",
    "\n",
    "model = clip_2fc(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for multilabel classification\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer with learning rate 0.001\n",
    "\n",
    "\n",
    "lr = 0.002\n",
    "warmup_epochs = 1\n",
    "warmup_constant_lr = 1e-5\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=warmup_epochs, T_mult=1, eta_min=warmup_constant_lr)\n",
    "\n",
    "criterion = AsymmetricLoss(3, 1) # Y_neg = 2, Y_pos = 1\n",
    "\n",
    "# Training loop\n",
    "best_model_state_dict = None\n",
    "best_loss = float('inf')\n",
    "num_epochs = 500\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/home/samyakr2/SHOP/weights/best_clip_1000_model.pth\"))\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    for features_batch, labels_batch in zip(train_features, train_labels):\n",
    "        # Flatten features batch\n",
    "        features_batch = features_batch.view(features_batch.size(0), -1).to(torch.float32)\n",
    "\n",
    "        # Convert labels to tensor\n",
    "        labels_tensor = labels_batch.type(torch.float32)\n",
    "        labels_tensor = labels_tensor.squeeze(dim=1)\n",
    "        # Forward pass\n",
    "        outputs = model(features_batch.to(device))\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels_tensor.to(device))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        outputs_np = outputs.cpu().detach().numpy()\n",
    "        labels_np = labels_tensor.cpu().detach().numpy()\n",
    "        all_outputs.append(outputs_np)\n",
    "        all_labels.append(labels_np)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss}\")\n",
    "    \n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)   \n",
    "    \n",
    "    avg_precision = average_precision_score(all_labels, all_outputs, average=None) ## macro\n",
    "    \n",
    "    \n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        best_model_state_dict = model.state_dict()\n",
    "        avg_p = avg_precision\n",
    "        np.save('/home/samyakr2/SHOP/train_gamma.npy', avg_p )\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(best_model_state_dict, f'/home/samyakr2/SHOP/weights/best_clip_{epoch + 1}_model.pth')\n",
    "#     torch.save(best_model_state_dict, \"/home/samyakr2/SHOP/weights/best_clip.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d53f0fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103,)\n",
      "Average Precision Score: [0.00136986 0.00578993 0.00678111 0.00847336 0.01282051 0.02095238\n",
      " 0.02464239 0.025      0.03395092 0.05473934 0.0645236  0.06596791\n",
      " 0.07178542 0.07486631 0.07588336 0.08539285 0.12510152 0.15149363\n",
      " 0.15447088 0.16210035 0.16671499 0.16696642 0.16949002 0.17234633\n",
      " 0.18980296 0.20312516 0.2088276  0.22452355 0.22595115 0.22887079\n",
      " 0.23622028 0.24575078 0.26797902 0.26938762 0.27631945 0.28448561\n",
      " 0.28762665 0.2958524  0.29929771 0.30824569 0.31632006 0.32623679\n",
      " 0.35233023 0.36568654 0.37032126 0.37661455 0.38211936 0.39241472\n",
      " 0.40270365 0.42421301 0.42475103 0.44125499 0.44618137 0.45729493\n",
      " 0.46189741 0.46870087 0.47222222 0.47538093 0.50655728 0.51424864\n",
      " 0.53765019 0.5525414  0.55637779 0.56659405 0.57249389 0.59489728\n",
      " 0.6051172  0.60819592 0.60857383 0.61128841 0.61846947 0.61943373\n",
      " 0.62197336 0.64617177 0.64880952 0.66282791 0.6652537  0.66915115\n",
      " 0.6716096  0.68157515 0.68191854 0.68498847 0.68723558 0.69222216\n",
      " 0.72418845 0.72479237 0.72658382 0.73612711 0.73780065 0.76173553\n",
      " 0.77227059 0.81243805 0.82667971 0.83309911 0.83415192 0.83553586\n",
      " 0.83556145 0.85780755 0.90257149 0.9141667  0.92709546 0.9369035\n",
      " 0.94180154]\n",
      "mAP from ASL 0.43725874711529916\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "def average_precision(output, target):\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    # sort examples\n",
    "    indices = output.argsort()[::-1]\n",
    "    # Computes prec@i\n",
    "    total_count_ = np.cumsum(np.ones((len(output), 1)))\n",
    "\n",
    "    target_ = target[indices]\n",
    "    ind = target_ == 1\n",
    "    pos_count_ = np.cumsum(ind)\n",
    "    total = pos_count_[-1]\n",
    "    pos_count_[np.logical_not(ind)] = 0\n",
    "    pp = pos_count_ / total_count_\n",
    "    precision_at_i_ = np.sum(pp)\n",
    "    precision_at_i = precision_at_i_ / (total + epsilon)\n",
    "\n",
    "    return precision_at_i\n",
    "\n",
    "\n",
    "def mAP(targs, preds):\n",
    "    \"\"\"Returns the model's average precision for each class\n",
    "    Return:\n",
    "        ap (FloatTensor): 1xK tensor, with avg precision for each class k\n",
    "    \"\"\"\n",
    "\n",
    "    if np.size(preds) == 0:\n",
    "        return 0\n",
    "    ap = np.zeros((preds.shape[1]))\n",
    "    # compute average precision for each class\n",
    "    for k in range(preds.shape[1]):\n",
    "        # sort scores\n",
    "        scores = preds[:, k]\n",
    "        targets = targs[:, k]\n",
    "        # compute average precision\n",
    "        ap[k] = average_precision(scores, targets)\n",
    "    return ap.mean()\n",
    "\n",
    "\n",
    "# Define a function for testing the model\n",
    "def test_model(model, criterion, features_batches, labels_batches, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    test_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for features_batch, labels_batch in zip(features_batches, labels_batches):\n",
    "            # Move batch to device\n",
    "            features_batch = features_batch.to(device)\n",
    "            labels_tensor = labels_batch.type(torch.float32).to(device)\n",
    "            labels_tensor = labels_tensor.squeeze(dim=1)\n",
    "        \n",
    "            \n",
    "            # Flatten features batch\n",
    "            features_batch = features_batch.view(features_batch.size(0), -1).to(torch.float32)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features_batch)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels_tensor)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Convert outputs and labels to numpy arrays\n",
    "            outputs_np = outputs.cpu().detach().numpy()\n",
    "            labels_np = labels_tensor.cpu().detach().numpy()\n",
    "\n",
    "            all_outputs.append(outputs_np)\n",
    "            all_labels.append(labels_np)\n",
    "\n",
    "    # Concatenate outputs and labels\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    # Compute average precision score\n",
    "    avg_precision = average_precision_score(all_labels, all_outputs, average=None) ## macro\n",
    "    print(avg_precision.shape)\n",
    "    answer_to_ = mAP(all_labels, all_outputs)\n",
    "    # Average tes tt loss\n",
    "    avg_test_loss = test_loss / len(features_batches)\n",
    "#     print(f\"Test Loss: {avg_test_loss}\")\n",
    "    print(f\"Average Precision Score: {np.sort(avg_precision)}\")\n",
    "    print('mAP from ASL', answer_to_)\n",
    "    return avg_precision\n",
    "\n",
    "for idx in range (500, 501, 10):\n",
    "    best_model_state_dict = torch.load(\"/home/samyakr2/SHOP/weights/best_clip_{}_model.pth\".format(idx))\n",
    "    model.load_state_dict(best_model_state_dict)\n",
    "    test_model(model, criterion, val_features, val_labels, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23ae8d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 18,  19,  33,  37,  59,  62,  68,  75,  89, 101, 102],\n",
      "       device='cuda:0')\n",
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "co_occurrence_matrix = torch.tensor(np.load('/home/samyakr2/SHOP/co_occurrence_matrix.npy')).to(device)\n",
    "initial_ap = torch.tensor(np.load('/home/samyakr2/SHOP/train_gamma.npy')).to(device)\n",
    "\n",
    "indices_less_than_0_3 = torch.nonzero(torch.lt(initial_ap, 0.3)).squeeze()\n",
    "print(indices_less_than_0_3)\n",
    "new_matrix = torch.zeros_like(co_occurrence_matrix)\n",
    "# new_matrix[indices_less_than_0_3] = co_occurrence_matrix[indices_less_than_0_3]\n",
    "\n",
    "top_neighbours = 1\n",
    "\n",
    "for idx in indices_less_than_0_3:\n",
    "    row = co_occurrence_matrix[idx]\n",
    "    top_indices = torch.argsort(row, descending=True)[:top_neighbours]\n",
    "    new_matrix[idx, top_indices] = row[top_indices]\n",
    "\n",
    "for i in range(103):\n",
    "    if i not in indices_less_than_0_3:\n",
    "        new_matrix[i, i] = co_occurrence_matrix[i, i]\n",
    "\n",
    "diagonal_values = torch.diag(new_matrix)\n",
    "normalized_matrix = new_matrix / diagonal_values[:, None]\n",
    "print(normalized_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4f72d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model_state_dict = torch.load(\"/home/samyakr2/SHOP/weights/best_clip_500_model.pth\")\n",
    "# model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "# similarity_text = (text_features @ text_features.T)\n",
    "# print(similarity_text)\n",
    "# normalized_similarity_text = torch.clamp(similarity_text, min=0, max=1)\n",
    "\n",
    "# indices_less_than_0_3 = torch.nonzero(torch.lt(initial_ap, 0.2)).squeeze()\n",
    "# print(indices_less_than_0_3)\n",
    "# new_matrix = torch.zeros_like(normalized_similarity_text)\n",
    "# # new_matrix[indices_less_than_0_3] = co_occurrence_matrix[indices_less_than_0_3]\n",
    "\n",
    "# top_neighbours = 50\n",
    "\n",
    "# for idx in indices_less_than_0_3:\n",
    "#     row = normalized_similarity_text[idx]\n",
    "#     top_indices = torch.argsort(row, descending=True)[:top_neighbours]\n",
    "#     new_matrix[idx, top_indices] = row[top_indices]\n",
    "\n",
    "# for i in range(103):\n",
    "#     if i not in indices_less_than_0_3:\n",
    "#         new_matrix[i, i] = normalized_similarity_text[i, i]\n",
    "\n",
    "# diagonal_values = torch.diag(new_matrix)\n",
    "# normalized_matrix = new_matrix / diagonal_values[:, None]\n",
    "# print(normalized_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ea794c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.7761, device='cuda:0', dtype=torch.float64) tensor(-5.0739, device='cuda:0', dtype=torch.float64)\n",
      "tensor(4.0475, device='cuda:0', dtype=torch.float64) tensor(-5.4273, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.1462, device='cuda:0', dtype=torch.float64) tensor(-4.5082, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.4567, device='cuda:0', dtype=torch.float64) tensor(-4.8754, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(4.4273, device='cuda:0', dtype=torch.float64) tensor(-5.3983, device='cuda:0', dtype=torch.float64)\n",
      "tensor(4.7456, device='cuda:0', dtype=torch.float64) tensor(-5.7744, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(2.9875, device='cuda:0', dtype=torch.float64) tensor(-4.6397, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.2823, device='cuda:0', dtype=torch.float64) tensor(-4.9732, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.2589, device='cuda:0', dtype=torch.float64) tensor(-5.6462, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.7828, device='cuda:0', dtype=torch.float64) tensor(-6.0395, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.5692, device='cuda:0', dtype=torch.float64) tensor(-6.4554, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.8258, device='cuda:0', dtype=torch.float64) tensor(-6.9051, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.2617, device='cuda:0', dtype=torch.float64) tensor(-4.8755, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.4962, device='cuda:0', dtype=torch.float64) tensor(-5.2151, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.7367, device='cuda:0', dtype=torch.float64) tensor(-5.5467, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.9970, device='cuda:0', dtype=torch.float64) tensor(-5.9331, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.4736, device='cuda:0', dtype=torch.float64) tensor(-5.0703, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.7233, device='cuda:0', dtype=torch.float64) tensor(-5.4235, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.6206, device='cuda:0', dtype=torch.float64) tensor(-5.3050, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.8809, device='cuda:0', dtype=torch.float64) tensor(-6.2263, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.7736, device='cuda:0', dtype=torch.float64) tensor(-5.2143, device='cuda:0', dtype=torch.float64)\n",
      "tensor(4.0448, device='cuda:0', dtype=torch.float64) tensor(-5.5775, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.9105, device='cuda:0', dtype=torch.float64) tensor(-5.6932, device='cuda:0', dtype=torch.float64)\n",
      "tensor(4.2964, device='cuda:0', dtype=torch.float64) tensor(-6.0898, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.8460, device='cuda:0', dtype=torch.float64) tensor(-5.0642, device='cuda:0', dtype=torch.float64)\n",
      "tensor(4.1225, device='cuda:0', dtype=torch.float64) tensor(-5.5198, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.2043, device='cuda:0', dtype=torch.float64) tensor(-5.6061, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.4346, device='cuda:0', dtype=torch.float64) tensor(-5.9966, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(4.4375, device='cuda:0', dtype=torch.float64) tensor(-6.6750, device='cuda:0', dtype=torch.float64)\n",
      "tensor(4.7565, device='cuda:0', dtype=torch.float64) tensor(-7.1399, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(4.7638, device='cuda:0', dtype=torch.float64) tensor(-5.1023, device='cuda:0', dtype=torch.float64)\n",
      "tensor(5.1062, device='cuda:0', dtype=torch.float64) tensor(-5.4577, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(4.0204, device='cuda:0', dtype=torch.float64) tensor(-6.3329, device='cuda:0', dtype=torch.float64)\n",
      "tensor(4.3095, device='cuda:0', dtype=torch.float64) tensor(-6.7740, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.3913, device='cuda:0', dtype=torch.float64) tensor(-7.0165, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.6351, device='cuda:0', dtype=torch.float64) tensor(-7.5053, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.6812, device='cuda:0', dtype=torch.float64) tensor(-5.0687, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.9458, device='cuda:0', dtype=torch.float64) tensor(-5.4218, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.1436, device='cuda:0', dtype=torch.float64) tensor(-5.9740, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.3696, device='cuda:0', dtype=torch.float64) tensor(-6.3902, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(3.0937, device='cuda:0', dtype=torch.float64) tensor(-6.1328, device='cuda:0', dtype=torch.float64)\n",
      "tensor(3.3161, device='cuda:0', dtype=torch.float64) tensor(-6.5601, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "tensor(2.0385, device='cuda:0', dtype=torch.float64) tensor(-5.5403, device='cuda:0', dtype=torch.float64)\n",
      "tensor(2.4018, device='cuda:0', dtype=torch.float64) tensor(-5.9263, device='cuda:0', dtype=torch.float64)\n",
      "---------------------------------------------\n",
      "[0.00136986 0.00578993 0.00678111 0.00847336 0.01282051 0.02095238\n",
      " 0.02464239 0.025      0.03395092 0.05473934 0.0645236  0.06596791\n",
      " 0.07178542 0.07486631 0.07588336 0.08539285 0.12510152 0.15149363\n",
      " 0.15447088 0.16210035 0.16671499 0.16696642 0.16949002 0.17234633\n",
      " 0.18980296 0.20312516 0.2088276  0.22452355 0.22595115 0.22887079\n",
      " 0.23622028 0.24575078 0.26797902 0.26938762 0.27631945 0.28448561\n",
      " 0.28762665 0.2958524  0.29929771 0.30824569 0.31632006 0.32623679\n",
      " 0.35233023 0.36568654 0.37032126 0.37661455 0.38211936 0.39241472\n",
      " 0.40270365 0.42421301 0.42475103 0.44125499 0.44618137 0.45729493\n",
      " 0.46189741 0.46870087 0.47222222 0.47538093 0.50655728 0.51424864\n",
      " 0.53765019 0.5525414  0.55637779 0.56659405 0.57249389 0.59489728\n",
      " 0.6051172  0.60819592 0.60857383 0.61128841 0.61846947 0.61943373\n",
      " 0.62197336 0.64617177 0.64880952 0.66282791 0.6652537  0.66915115\n",
      " 0.6716096  0.68157515 0.68191854 0.68498847 0.68723558 0.69222216\n",
      " 0.72418845 0.72479237 0.72658382 0.73612711 0.73780065 0.76173553\n",
      " 0.77227059 0.81243805 0.82667971 0.83309911 0.83415192 0.83553586\n",
      " 0.83556145 0.85780755 0.90257149 0.9141667  0.92709546 0.9369035\n",
      " 0.94180154]\n",
      "0.4372623360894657\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "best_model_state_dict = torch.load(\"/home/samyakr2/SHOP/weights/best_clip_500_model.pth\")\n",
    "model.load_state_dict(best_model_state_dict)\n",
    "\n",
    "# similarity_text = (text_features @ text_features.T)\n",
    "# normalized_similarity_text = F.normalize(similarity_text, p=2, dim=1)\n",
    "# normalized_similarity_text = torch.clamp(similarity_text, min=0, max=1)\n",
    "# normalized_similarity_text = normalized_similarity_text / 10\n",
    "\n",
    "# Set diagonals to 1\n",
    "# y = normalized_similarity_text.fill_diagonal_(1)\n",
    "\n",
    "# normalized_co_occurrence_matrix = np.load('/home/samyakr2/SHOP/normalized_foodseg103_co_occurrence_matrix.npy')\n",
    "# normalized_co_occurrence_matrix = torch.tensor(normalized_co_occurrence_matrix).to(device)\n",
    "\n",
    "# y = torch.eye(len(normalized_co_occurrence_matrix)).to(device)\n",
    "\n",
    "# normalized_matrix\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "test_loss = 0.0\n",
    "co_occurrence_matrix = torch.tensor(np.load('/home/samyakr2/SHOP/co_occurrence_matrix.npy')).to(device)\n",
    "all_labels = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad(): # Disable gradient computation\n",
    "\n",
    "        \n",
    "#         indices_less_than_0_3 = torch.nonzero(torch.lt(initial_ap, 0.1)).squeeze()\n",
    "#         new_matrix = torch.zeros_like(co_occurrence_matrix)\n",
    "#         new_matrix[indices_less_than_0_3] = co_occurrence_matrix[indices_less_than_0_3]\n",
    "\n",
    "#         for i in range(103):\n",
    "#             if i not in indices_less_than_0_3:\n",
    "#                 new_matrix[i, i] = co_occurrence_matrix[i, i]\n",
    "\n",
    "#         diagonal_values = torch.diag(new_matrix)\n",
    "#         normalized_matrix = new_matrix / diagonal_values[:, None]\n",
    "\n",
    "    for features_batch, labels_batch in zip(val_features, val_labels):\n",
    "        # Move batch to device\n",
    "        features_batch = features_batch.to(device)\n",
    "        labels_tensor = labels_batch.type(torch.float32).to(device)\n",
    "        labels_tensor = labels_tensor.squeeze(dim=1)\n",
    "        features_batch = features_batch.view(features_batch.size(0), -1).to(torch.float32)\n",
    "\n",
    "            # Forward pass\n",
    "        outputs = model(features_batch)\n",
    "#         outputs = torch.sigmoid(outputs)\n",
    "        outputs_reshaped = outputs.unsqueeze(1)\n",
    "#         print(outputs_reshaped.shape)\n",
    "#         print(normalized_similarity_text.unsqueeze(0).shape)\n",
    "#         print((outputs_reshaped * normalized_similarity_text.unsqueeze(0)).shape)\n",
    "#         result = torch.sum(outputs_reshaped * normalized_similarity_text.unsqueeze(0), dim =2)\n",
    "#         result = torch.sum(outputs_reshaped * normalized_co_occurrence_matrix.unsqueeze(0), dim =2)\n",
    "#         print('-'*5,torch.max(normalized_matrix), torch.min(normalized_matrix))\n",
    "#         print(normalized_matrix.shape)\n",
    "        result = torch.sum(outputs_reshaped * normalized_matrix.unsqueeze(0), dim =2)\n",
    "#         print(torch.max(result), torch.min(result))\n",
    "#         normalized_matrix\n",
    "        pred = initial_ap*result\n",
    "        print(torch.max(pred), torch.min(pred))\n",
    "        print(torch.max(result), torch.min(result))\n",
    "        print('-'*45)\n",
    "\n",
    "        outputs_np = pred.cpu().detach().numpy()\n",
    "        labels_np = labels_tensor.cpu().detach().numpy()\n",
    "\n",
    "        all_outputs.append(outputs_np)\n",
    "        all_labels.append(labels_np)\n",
    "\n",
    "\n",
    "#         initial_ap*normalized_similarity_text*outputs\n",
    "    all_outputs = np.concatenate(all_outputs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    avg_precision = average_precision_score(all_labels, all_outputs, average=None) ## macro\n",
    "    print(np.sort(avg_precision)) \n",
    "    avg_precision = average_precision_score(all_labels, all_outputs, average='macro') ## macro\n",
    "    print(avg_precision)\n",
    "    print('-'*25)\n",
    "#         initial_ap = torch.tensor(avg_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5649a689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 19,  59, 102, 101,  37,  18,  89,  75,  62,  68,  33,  42,  15,  96,\n",
       "          8,  97,  82,  49,  70,  99,  78,  90,  34,  22,   1,  50,  76,  21,\n",
       "         85,  26, 100,  91,  77,  32,  46,  52,  44,  41,  14,  92,  93,   0,\n",
       "          3,  71,  25,  39,  16,  27,  48,  43,  38,  56,  80,  74,  24,  51,\n",
       "         67,  17,  60,  61,  10,  66,  87,  35,  30,  53,   4,  13,   6,  88,\n",
       "         20,  95,  81,   7,  63,  47,  79,  28,  23,  45,   5,  40,  11,  84,\n",
       "         98,   2,  54,   9,  69,  36,  94,  57,  72,  31,  55,  65,  64,  12,\n",
       "         58,  29,  86,  83,  73], device='cuda:0')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_ap = torch.tensor(np.load('/home/samyakr2/SHOP/train_gamma.npy')).to(device)\n",
    "values, indices = initial_ap.sort()\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f9676179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.2222, 0.0556, 0.0000, 0.1111, 0.0000,\n",
       "        0.1111, 0.0000, 0.0000, 0.0556, 0.0556, 0.0000, 0.0000, 0.1111, 0.0000,\n",
       "        0.0556, 1.0000, 0.0000, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0556, 0.0556, 0.0000, 0.0000, 0.1111, 0.0000, 0.0000,\n",
       "        0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0556, 0.0000,\n",
       "        0.0000, 0.0000, 0.0556, 0.0556, 0.0000, 0.0556, 0.1111, 0.0000, 0.0000,\n",
       "        0.0000, 0.0556, 0.0000, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.1667, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.0556,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.1111, 0.0000, 0.0000, 0.1111, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0556, 0.0000, 0.0000, 0.0556, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_matrix[19, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67c6b7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0183, 0.1000, 0.0000, 0.0031, 0.0000,\n",
       "        0.0060, 0.0000, 0.0000, 0.0079, 0.0078, 0.0000, 0.0000, 0.0286, 0.0000,\n",
       "        0.0769, 1.0000, 0.0000, 0.0244, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0026, 0.0063, 0.0000, 0.0000, 0.0465, 0.0000, 0.0000,\n",
       "        0.0024, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0055, 0.0000,\n",
       "        0.0000, 0.0000, 0.0012, 0.0051, 0.0000, 0.0141, 0.0024, 0.0000, 0.0000,\n",
       "        0.0000, 0.0101, 0.0000, 0.0010, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0065, 0.0025, 0.0000, 0.0000, 0.0000, 0.0000, 0.0064,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0023, 0.0000, 0.0000, 0.0028, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0027, 0.0000, 0.0000, 0.0040, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_matrix[:, 19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9685d5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.0000, 0.0000, 0.0204, 0.0413, 0.3000, 0.0000, 0.0000, 0.0072,\n",
       "        0.0090], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_matrix[:,0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5137bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 19,  59, 102, 101,  37,  18,  89,  75,  62,  68,  33,  42,  15,  96,\n",
       "          8,  97,  82,  49,  70,  99,  78,  90,  34,  22,   1,  50,  76,  21,\n",
       "         85,  26, 100,  91,  77,  32,  46,  52,  44,  41,  14,  92,  93,   0,\n",
       "          3,  71,  25,  39,  16,  27,  48,  43,  38,  56,  80,  74,  24,  51,\n",
       "         67,  17,  60,  61,  10,  66,  87,  35,  30,  53,   4,  13,   6,  88,\n",
       "         20,  95,  81,   7,  63,  47,  79,  28,  23,  45,   5,  40,  11,  84,\n",
       "         98,   2,  54,   9,  69,  36,  94,  57,  72,  31,  55,  65,  64,  12,\n",
       "         58,  29,  86,  83,  73], device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52f7175a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0183, device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_matrix[4,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6128607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1000, 0.0769, 0.0465, 0.0286], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([19,  5, 18, 33, 16], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2222, 0.1667, 0.1111, 0.1111], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([19,  4, 65,  9,  7], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0120, 0.0081, 0.0064, 0.0054], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([59,  2, 40, 71, 81], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4000, 0.4000, 0.4000, 0.2000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([59, 81,  2, 51, 40], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1333, 0.1000, 0.0833, 0.0822], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([102,  78,   5,  67,  70], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2323, 0.2129, 0.2000, 0.1871], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([102,  57,  45,  72,  47], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0667, 0.0185, 0.0175, 0.0100], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([101,  78,  76,  63,  28], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2500, 0.2500, 0.2500, 0.1667], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([101,  83,  47,  72,  23], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0732, 0.0455, 0.0435, 0.0325], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([37, 21, 26, 77, 40], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2667, 0.2333, 0.1667, 0.1333], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([37, 51, 57,  7,  9], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.2857, 0.1000, 0.0556], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([18, 85, 22,  5, 19], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2308, 0.2308, 0.1538, 0.1538], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([18, 65, 57,  8,  4], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0556, 0.0548, 0.0382, 0.0366], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([89, 82, 70, 71, 97], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.5833, 0.2292, 0.2083, 0.2083], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([89, 83, 93, 86, 47], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.3333, 0.2083, 0.1429], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([75, 98, 85, 67, 52], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2406, 0.2180, 0.1955, 0.1729], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([75, 83, 72, 47, 51], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0185, 0.0086, 0.0051, 0.0040], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([62, 76, 51, 48, 95], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.7778, 0.2222, 0.2222, 0.1111], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([62, 51, 83, 86, 36], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0417, 0.0393, 0.0366, 0.0319], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([68, 91, 93, 97, 90], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.6316, 0.3158, 0.2632, 0.2632], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([68, 93, 72, 92, 88], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1111, 0.1034, 0.0526, 0.0500], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([33, 19, 44, 41, 17], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1628, 0.1628, 0.1395, 0.1395], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([33, 88, 29, 66, 47], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2500, 0.1379, 0.1316, 0.0650], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([42,  6, 44, 41, 40], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4500, 0.4000, 0.3000, 0.2500], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([42, 29, 40, 88, 41], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0273, 0.0150, 0.0137, 0.0125], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([15, 43,  9, 35, 11], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.2083, 0.2083, 0.2083], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([15, 57, 43, 36,  9], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.0833, 0.0488, 0.0417], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([96, 98, 91, 97, 67], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4000, 0.4000, 0.3000, 0.3000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([96, 97, 83, 88, 46], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1905, 0.1860, 0.1667, 0.1538], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 8, 38, 34, 91, 18], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4746, 0.2862, 0.1739, 0.1630], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 8, 57, 72, 79, 45], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.5000, 0.4000, 0.1579, 0.1429], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([97, 98, 96, 68, 99], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2805, 0.2805, 0.2317, 0.2195], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([97, 83, 45, 72, 92], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1429, 0.1429, 0.0667, 0.0500], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([82, 99, 25, 78, 17], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.5278, 0.4167, 0.3333, 0.2778], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([82, 83, 51, 72, 81], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1250, 0.0987, 0.0938, 0.0702], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([49, 91, 23, 20, 27], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2273, 0.2143, 0.1948, 0.1429], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([49, 72, 51, 57, 23], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2174, 0.1429, 0.1333, 0.1053], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([70, 77, 99, 54, 68], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3562, 0.3562, 0.2329, 0.2192], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([70, 92, 88, 93, 83], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0333, 0.0278, 0.0208, 0.0185], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([99, 54, 82, 67, 76], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2857, 0.2857, 0.2857, 0.2857], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([99, 83, 46, 86, 72], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0833, 0.0500, 0.0278, 0.0208], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 78, 101,  17,  82,  67], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2667, 0.2000, 0.1333, 0.1333], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([78,  7, 93, 47, 45], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1579, 0.1429, 0.0667, 0.0500], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([90, 68, 99, 54, 42], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4043, 0.3404, 0.2979, 0.2447], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([90, 83, 69, 45, 72], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0526, 0.0476, 0.0461, 0.0333], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([34, 61, 38, 81, 37], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3953, 0.3256, 0.2093, 0.2093], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([34, 81, 72, 69, 51], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1538, 0.0488, 0.0429, 0.0213], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([22, 18, 21, 16, 32], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4286, 0.4286, 0.2857, 0.2857], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([22, 72, 16, 18,  4], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0222, 0.0094, 0.0046, 0.0026], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 1, 14, 24,  4, 29], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.3333, 0.3333, 0.3333], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 1, 24,  4, 29, 14], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1053, 0.0921, 0.0588, 0.0556], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([50, 68, 94, 84, 19], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4507, 0.3521, 0.1972, 0.1831], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([50, 69, 83, 94, 88], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1429, 0.1111, 0.0833, 0.0625], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 76,  99,  62, 101,  20], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.3148, 0.2778, 0.2037], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([76, 69, 47, 83, 72], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2857, 0.1538, 0.1429, 0.1000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([21, 22, 18, 25, 37], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2683, 0.1707, 0.1707, 0.1707], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([21,  4, 24,  9,  7], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 1.0000, 0.0769, 0.0208, 0.0075], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([73, 85, 18, 67, 75], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.3333, 0.3333, 0.3333], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([85, 67, 18, 73, 46], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0408, 0.0333, 0.0310, 0.0250], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([26,  3, 37, 13, 11], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2273, 0.2273, 0.1818, 0.1364], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([26, 88,  7, 13, 51], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0833, 0.0573, 0.0556, 0.0548], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([100,  91,  71,  60,  70], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3131, 0.2929, 0.2525, 0.2525], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([100,  86,  69,  83,  45], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2000, 0.1667, 0.0833, 0.0526], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([91, 96, 98, 67, 68], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.2500, 0.2500, 0.2500], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([91, 88, 79, 72, 45], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0685, 0.0476, 0.0465, 0.0444], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([77, 70,  0, 13, 14], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3478, 0.2609, 0.2609, 0.2174], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([77, 36, 88, 13, 51], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2500, 0.1429, 0.1053, 0.1000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([32,  6, 22, 41, 42], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2979, 0.2979, 0.2979, 0.2979], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([32, 30,  7, 57, 29], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.5000, 0.3333, 0.3000, 0.2857], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([46, 98, 85, 96, 99], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2785, 0.2152, 0.2004, 0.1582], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([46, 69, 86, 83, 57], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0667, 0.0404, 0.0150, 0.0107], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([52, 54, 55, 75, 64], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3571, 0.2857, 0.2857, 0.2143], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([52, 51, 55, 36, 57], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2000, 0.0698, 0.0426, 0.0278], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([44, 42, 33, 39, 82], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3103, 0.1724, 0.1379, 0.1379], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([44, 88, 66, 39,  8], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2500, 0.1138, 0.1064, 0.0851], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([41, 42, 40, 39, 32], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.6842, 0.3684, 0.3684, 0.2632], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([41, 29, 40,  7, 39], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.0952, 0.0870, 0.0488], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([14,  1,  0, 77, 21], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2000, 0.1556, 0.0889, 0.0889], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([14,  4, 57, 28,  9], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3562, 0.2632, 0.2195, 0.2143], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([92, 70, 68, 97, 52], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3529, 0.3262, 0.2781, 0.2032], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([92, 72, 45, 57, 79], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.6316, 0.2561, 0.2329, 0.2292], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([93, 68, 87, 70, 89], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3311, 0.2754, 0.2197, 0.2033], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([93, 72, 83, 81, 51], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3000, 0.0444, 0.0435, 0.0413], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 0,  5, 14, 77,  4], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4286, 0.1429, 0.1429, 0.0952], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([0, 4, 5, 9, 8], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1000, 0.0909, 0.0541, 0.0476], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 3,  5, 26,  9,  0], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3673, 0.3469, 0.3061, 0.1837], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 3,  9, 29,  7,  4], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2000, 0.1520, 0.1250, 0.1111], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([71, 59, 86, 89, 82], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.6815, 0.5478, 0.2675, 0.2611], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([71, 86, 83, 47, 69], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0500, 0.0278, 0.0244, 0.0149], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([25, 17, 82, 21, 56], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4286, 0.2857, 0.1429, 0.1429], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([25,  4, 47, 16,  9], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2632, 0.2000, 0.1379, 0.0900], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([39, 41, 42, 44, 28], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2447, 0.2234, 0.1596, 0.1064], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([39, 29,  7, 88, 40], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4286, 0.1538, 0.1429, 0.1220], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([16, 22, 18, 25, 21], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2714, 0.1857, 0.1571, 0.1286], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([16,  4,  9, 57,  7], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2000, 0.1429, 0.1429, 0.0833], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([27, 17, 74, 22, 91], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4386, 0.3158, 0.2105, 0.1930], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([27, 72, 57, 88, 79], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1480, 0.1429, 0.1429, 0.1250], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([48, 23, 52, 74, 20], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3282, 0.1795, 0.1692, 0.1641], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([48, 57, 51, 23, 69], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2105, 0.2083, 0.1707, 0.1500], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([43, 41, 15, 40, 42], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1694, 0.1475, 0.1366, 0.1311], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([43, 57, 51, 66, 29], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0488, 0.0286, 0.0233, 0.0208], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([38, 21, 16, 34, 10], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2857, 0.2857, 0.1905, 0.1429], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([38, 57, 51,  8, 46], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1429, 0.1429, 0.0685, 0.0556], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([56, 74, 25, 70, 80], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2985, 0.2388, 0.1194, 0.1194], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([56, 57, 88, 83, 72], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1429, 0.1053, 0.1000, 0.1000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([80, 25, 68, 17,  5], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2222, 0.1667, 0.1528, 0.1389], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([80, 57, 92, 88, 93], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0417, 0.0175, 0.0149, 0.0107], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([74, 67, 27, 56, 64], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2857, 0.2857, 0.2857, 0.2857], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([74, 65, 23, 67, 64], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.1707, 0.1429, 0.1220], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([24,  1, 21, 22, 40], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2358, 0.1604, 0.1415, 0.1415], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([24, 57, 51, 40,  9], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.7778, 0.4737, 0.4167, 0.4000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([51, 62, 61, 82, 59], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2347, 0.1883, 0.1797, 0.1687], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([51, 57, 72, 45, 83], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 1.0000, 0.6667, 0.3333, 0.2857], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([73, 67, 98, 85, 74], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2083, 0.2083, 0.1458, 0.1458], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([67, 88, 75, 72, 65], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1429, 0.0702, 0.0667, 0.0417], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([17, 25, 27, 78, 91], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3000, 0.3000, 0.2500, 0.2000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([17, 88, 65, 47, 23], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0500, 0.0312, 0.0303, 0.0274], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 60,  42,  10, 100,  35], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2778, 0.1481, 0.1296, 0.1296], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([60, 72, 57, 93, 83], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0233, 0.0135, 0.0110, 0.0094], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([61, 34, 23, 51, 24], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4737, 0.1579, 0.1579, 0.1579], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([61, 51, 88, 79, 23], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1333, 0.1304, 0.1000, 0.0952], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([10, 54, 77,  5, 38], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2292, 0.1979, 0.1979, 0.1562], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([10, 45, 51, 88, 57], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2105, 0.1724, 0.1500, 0.1489], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([66, 31, 44, 42, 32], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2343, 0.2015, 0.1662, 0.1461], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([66, 51, 72, 88,  7], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1429, 0.1377, 0.1294, 0.1111], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([87, 22, 93, 83, 82], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.6951, 0.3476, 0.3415, 0.2561], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([87, 83,  7, 51, 93], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2500, 0.1375, 0.1064, 0.0620], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([35,  6, 11, 32, 13], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2329, 0.1644, 0.1507, 0.1096], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([35,  7,  9, 11, 13], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2979, 0.1862, 0.1500, 0.1429], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([30, 32,  9, 42,  3], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3899, 0.2893, 0.1447, 0.1258], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([30,  9,  7, 57, 31], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2364, 0.1667, 0.1429, 0.1429], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([53, 36, 98, 99, 52], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3876, 0.2829, 0.2558, 0.2287], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([53, 36, 83, 86, 72], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4286, 0.4286, 0.3333, 0.3000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 4, 25,  0,  1,  5], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2156, 0.1651, 0.1468, 0.1468], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 4,  7, 51, 83, 12], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2609, 0.1818, 0.1096, 0.1038], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([13, 77, 26, 35, 43], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2868, 0.1473, 0.1240, 0.1008], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([13, 36, 43, 57, 88], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0500, 0.0213, 0.0137, 0.0132], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 6, 42, 32, 35, 31], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.5000, 0.5000, 0.2500, 0.2500], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 6, 31, 29, 35, 32], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 1.0000, 0.3562, 0.3333, 0.3333], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([73, 88, 70, 91, 85], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2799, 0.2138, 0.1918, 0.1604], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([88, 72, 83, 51, 57], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.0370, 0.0351, 0.0233, 0.0205], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([20, 76, 63, 33, 48], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2812, 0.2812, 0.2500, 0.2500], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([20, 47, 45, 57, 46], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1667, 0.1429, 0.1338, 0.1121], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([95, 98, 99, 71, 69], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3478, 0.3399, 0.2688, 0.2174], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([95, 69, 83, 47, 45], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4000, 0.3953, 0.2778, 0.2439], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([81, 59, 34, 82, 87], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3388, 0.2710, 0.2493, 0.2276], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([81, 72, 83, 51, 57], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3711, 0.3684, 0.3476, 0.3092], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 7, 29, 41, 87, 31], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2264, 0.1855, 0.1808, 0.1289], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 7, 29, 83, 57,  9], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1667, 0.1250, 0.0542, 0.0526], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 63, 101,  20,  47,  61], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4035, 0.2807, 0.1754, 0.1579], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([63, 47, 86, 72, 46], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4332, 0.4035, 0.3438, 0.3148], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([47, 65, 63, 86, 76], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2854, 0.2406, 0.2370, 0.2123], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([47, 86, 83, 65, 69], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.2937, 0.2500, 0.2229], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([79, 98, 72, 91,  2], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.5757, 0.4392, 0.2804, 0.2233], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([79, 72, 57, 45, 51], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2375, 0.1163, 0.1132, 0.1000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([28, 11, 33, 24, 17], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3500, 0.2400, 0.1900, 0.1800], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([28, 29, 57, 11,  9], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2857, 0.2083, 0.2000, 0.1692], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([23, 74, 91, 17, 48], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3274, 0.2197, 0.1570, 0.1525], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([23, 57, 72, 51, 88], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3916, 0.3262, 0.3248, 0.2979], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([45,  2, 92, 69, 90], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3503, 0.2857, 0.2404, 0.2184], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([45, 69, 57, 83, 72], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1429, 0.0769, 0.0556, 0.0204], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 5,  0, 18, 19,  3], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3000, 0.3000, 0.2000, 0.1000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 5,  4,  0, 51,  2], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4000, 0.3684, 0.2500, 0.2000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([40, 42, 41,  6, 59], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3171, 0.2520, 0.2439, 0.1707], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([40, 57,  7, 29, 43], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1900, 0.1507, 0.0909, 0.0698], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([11, 28, 35, 26, 33], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3250, 0.2375, 0.1375, 0.1125], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([11, 29, 28, 35, 43], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.2000, 0.1549, 0.1538], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([84, 85, 96, 50, 18], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3048, 0.2834, 0.1979, 0.1604], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([84, 69, 83, 45, 51], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2000, 0.0833, 0.0417, 0.0366], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([98, 96, 67, 91, 97], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.6667, 0.5000, 0.5000, 0.5000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([98, 67, 97, 83, 46], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4000, 0.1429, 0.1000, 0.1000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 2, 59, 22, 96,  5], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4759, 0.3916, 0.3795, 0.2711], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 2, 57, 45, 51, 72], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1429, 0.1429, 0.0548, 0.0417], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([54, 99, 52, 70, 10], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3667, 0.2000, 0.2000, 0.1667], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([54, 57, 64, 88, 36], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3899, 0.3673, 0.2603, 0.2566], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 9, 30,  3, 29, 31], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3033, 0.2462, 0.1862, 0.1171], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 9, 29,  7, 30, 31], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4507, 0.4474, 0.3503, 0.3478], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([69, 50, 94, 45, 95], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3643, 0.3248, 0.2357, 0.2293], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([69, 83, 45, 86, 47], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3876, 0.3478, 0.2868, 0.2857], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([36, 53, 77, 13, 52], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2364, 0.2270, 0.1678, 0.1277], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([36, 53, 88, 47, 51], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1972, 0.0866, 0.0659, 0.0625], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([94, 50, 69, 53, 10], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4474, 0.3224, 0.2368, 0.2039], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([94, 69, 83, 47, 45], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4759, 0.4746, 0.4392, 0.3667], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([57,  2,  8, 79, 54], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2371, 0.2099, 0.1937, 0.1786], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([57, 72, 45, 51, 79], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.5757, 0.4386, 0.4286, 0.3529], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([72, 79, 27, 22, 92], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2975, 0.2937, 0.2253, 0.2013], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([72, 57, 79, 88, 45], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.5000, 0.2368, 0.2340, 0.1675], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([31,  6, 41, 32, 29], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4276, 0.3092, 0.2566, 0.2105], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([31, 29,  7,  9, 66], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2857, 0.0856, 0.0769, 0.0690], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([55, 52, 64, 18, 44], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1818, 0.1717, 0.1717, 0.1616], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([55, 86, 65, 36, 64], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3000, 0.2857, 0.2370, 0.2308], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([65, 17, 74, 47, 18], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.4332, 0.3103, 0.2349, 0.1444], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([65, 47, 86, 83, 46], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2857, 0.2105, 0.2000, 0.1616], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([64, 74, 68, 54, 55], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.2834, 0.2353, 0.1658, 0.1604], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([64, 47, 86, 83, 45], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1468, 0.1429, 0.1020, 0.0952], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([12,  4, 22,  3,  0], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3386, 0.2520, 0.1811, 0.1496], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([12, 57,  4,  9,  7], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.1562, 0.1429, 0.1376, 0.1287], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([58, 20, 52, 69, 46], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3149, 0.3120, 0.2624, 0.1924], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([58, 69, 47, 45, 57], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.6842, 0.5000, 0.4500, 0.4276], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([29, 41,  6, 42, 31], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3711, 0.2603, 0.2397, 0.1675], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([29,  7,  9, 57, 31], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.6815, 0.3131, 0.3103, 0.2857], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([ 86,  71, 100,  65,  99], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3438, 0.3338, 0.2628, 0.2045], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([86, 47, 83, 69, 65], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.6951, 0.5833, 0.5478, 0.5278], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([83, 87, 89, 71, 82], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3246, 0.2667, 0.2316, 0.1986], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([83, 69, 86, 47, 45], device='cuda:0'))\n",
      "---------------------------------------------\n",
      "torch.return_types.topk(\n",
      "values=tensor([1.0000, 0.3333, 0.0208, 0.0016, 0.0000], device='cuda:0',\n",
      "       dtype=torch.float64),\n",
      "indices=tensor([73, 85, 67, 88,  0], device='cuda:0'))\n",
      "torch.return_types.topk(\n",
      "values=tensor([1., 1., 1., 1., 0.], device='cuda:0', dtype=torch.float64),\n",
      "indices=tensor([73, 67, 85, 88,  0], device='cuda:0'))\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "co_occurrence_matrix = torch.tensor(np.load('/home/samyakr2/SHOP/normalized_foodseg103_co_occurrence_matrix.npy')).to(device)\n",
    "for idx in indices:\n",
    "\n",
    "    y = co_occurrence_matrix[idx,:].topk(5)\n",
    "    y_as = co_occurrence_matrix[:,idx].topk(5)\n",
    "    print(y_as)\n",
    "    print(y)\n",
    "#     for idx2 in y.indices:\n",
    "#         print(co_occurrence_matrix[idx2,idx])\n",
    "    print('-'*45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf62c3d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_neighbours = []\n",
    "# first_neighbours_as = []\n",
    "for ele, ele_as in zip(y,y_as):\n",
    "    print(ele.topk(5))\n",
    "    print(ele_as.topk(5))\n",
    "    print('-'*20)\n",
    "    first_neighbours.append(ele.topk(5).indices [1])\n",
    "    first_neighbours_as.append(ele_as.topk(5).indices [1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29dfc67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 81, 57, 83, 51, 65, 83, 83, 51, 93], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN =  torch.stack(first_neighbours)\n",
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c17b88dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = co_occurrence_matrix[FN][:10]\n",
    "z_as = co_occurrence_matrix[:,FN][:10]\n",
    "for ele, ele_as in zip(z,z_as):\n",
    "    print(ele.topk(5))\n",
    "    print(ele_as.topk(5))\n",
    "    print('-'*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334007b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
